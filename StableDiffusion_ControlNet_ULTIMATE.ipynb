{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callmeATHUL/AETHER-QUANT/blob/main/StableDiffusion_ControlNet_ULTIMATE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BlQ2GUDJcKE"
      },
      "outputs": [],
      "source": [
        "# ULTIMATE AI AUTOMATION SUITE\n",
        "## Stable Diffusion + ControlNet + API + n8n Integration\n",
        "\n",
        "# PROFESSIONAL-GRADE AI IMAGE GENERATION ON FREE GOOGLE COLAB!\n",
        "\n",
        "### Features:\n",
        "# Latest Stable Diffusion WebUI\n",
        "# ControlNet with all major models\n",
        "# Public API access via ngrok\n",
        "# n8n automation ready\n",
        "# Batch processing capabilities\n",
        "# Professional API client\n",
        "\n",
        "# CLICK THE CELLS BELOW TO START YOUR AI EMPIRE!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "q35z9lsYOHcq",
        "outputId": "bf54e5db-cb25-4f59-975f-aaaddfb6ac1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting AI Automation Suite Setup...\n",
            "üîß Installing system dependencies...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-84937384.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Install system packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mrun_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"apt-get update -qq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mrun_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"apt-get install -y -qq wget git python3-pip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Install Python packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-84937384.py\u001b[0m in \u001b[0;36mrun_cmd\u001b[0;34m(cmd, live)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ùå Error: {result.stderr}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title üõ†Ô∏è **STEP 1: Setup Environment** {display-mode: \"form\"}\n",
        "#@markdown This installs all dependencies and sets up the environment\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def run_cmd(cmd, live=False):\n",
        "    if live:\n",
        "        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            print(line, end='')\n",
        "        process.wait()\n",
        "    else:\n",
        "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"‚ùå Error: {result.stderr}\")\n",
        "        return result.stdout\n",
        "\n",
        "print(\"üöÄ Starting AI Automation Suite Setup...\")\n",
        "print(\"üîß Installing system dependencies...\")\n",
        "\n",
        "# Install system packages\n",
        "run_cmd(\"apt-get update -qq\")\n",
        "run_cmd(\"apt-get install -y -qq wget git python3-pip\")\n",
        "\n",
        "# Install Python packages\n",
        "print(\"üêç Installing Python packages...\")\n",
        "run_cmd(\"pip install -q torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\")\n",
        "run_cmd(\"pip install -q xformers accelerate transformers diffusers\")\n",
        "run_cmd(\"pip install -q gradio fastapi uvicorn pyngrok\")\n",
        "run_cmd(\"pip install -q opencv-python-headless pillow numpy requests\")\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n",
        "\n",
        "# Test GPU\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"üéÆ GPU Detected: {gpu_name}\")\n",
        "    print(f\"üî• CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected - using CPU (slow)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oti_j11eJcKG"
      },
      "outputs": [],
      "source": [
        "#@title üé® **STEP 2: Install Stable Diffusion WebUI** {display-mode: \"form\"}\n",
        "#@markdown Downloads and sets up Automatic1111 WebUI with API access\n",
        "\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def run_cmd(cmd, live=False):\n",
        "    if live:\n",
        "        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
        "        for line in iter(process.stdout.readline, ''):\n",
        "            print(line, end='')\n",
        "        process.wait()\n",
        "    else:\n",
        "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"‚ùå Error: {result.stderr}\")\n",
        "        return result.stdout\n",
        "\n",
        "print(\"üé® Installing Stable Diffusion WebUI...\")\n",
        "\n",
        "# Clone WebUI if not exists\n",
        "if not os.path.exists('stable-diffusion-webui'):\n",
        "    print(\"üì• Downloading WebUI...\")\n",
        "    run_cmd(\"git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\")\n",
        "else:\n",
        "    print(\"‚ôªÔ∏è WebUI already exists, updating...\")\n",
        "    os.chdir('stable-diffusion-webui')\n",
        "    run_cmd(\"git pull\")\n",
        "    os.chdir('/content')\n",
        "\n",
        "print(\"‚úÖ WebUI installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDNraRHrJcKH"
      },
      "outputs": [],
      "source": [
        "#@title üéØ **STEP 3: Install ControlNet Extension** {display-mode: \"form\"}\n",
        "#@markdown Installs ControlNet extension and downloads essential models\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üéØ Installing ControlNet Extension...\")\n",
        "\n",
        "# Install ControlNet extension\n",
        "extensions_dir = Path('/content/stable-diffusion-webui/extensions')\n",
        "controlnet_dir = extensions_dir / 'sd-webui-controlnet'\n",
        "\n",
        "if not controlnet_dir.exists():\n",
        "    print(\"üì• Downloading ControlNet extension...\")\n",
        "    os.chdir(extensions_dir)\n",
        "    run_cmd(\"git clone https://github.com/Mikubill/sd-webui-controlnet.git\")\n",
        "    os.chdir('/content')\n",
        "else:\n",
        "    print(\"‚ôªÔ∏è ControlNet already exists, updating...\")\n",
        "    os.chdir(controlnet_dir)\n",
        "    run_cmd(\"git pull\")\n",
        "    os.chdir('/content')\n",
        "\n",
        "# Create ControlNet models directory\n",
        "models_dir = Path('/content/stable-diffusion-webui/models/ControlNet')\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download essential ControlNet models\n",
        "print(\"üì• Downloading ControlNet models...\")\n",
        "\n",
        "models_to_download = [\n",
        "    {\n",
        "        'name': 'control_v11p_sd15_canny.pth',\n",
        "        'url': 'https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "    },\n",
        "    {\n",
        "        'name': 'control_v11p_sd15_openpose.pth',\n",
        "        'url': 'https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "    },\n",
        "    {\n",
        "        'name': 'control_v11p_sd15_depth.pth',\n",
        "        'url': 'https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_depth.pth'\n",
        "    }\n",
        "]\n",
        "\n",
        "for model in models_to_download:\n",
        "    model_path = models_dir / model['name']\n",
        "    if not model_path.exists():\n",
        "        print(f\"üì• Downloading {model['name']}...\")\n",
        "        run_cmd(f\"wget -q -O '{model_path}' '{model['url']}'\")\n",
        "    else:\n",
        "        print(f\"‚úÖ {model['name']} already exists\")\n",
        "\n",
        "print(\"‚úÖ ControlNet setup complete!\")\n",
        "print(f\"üìÅ Models installed in: {models_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJfpCpNwgHLE"
      },
      "outputs": [],
      "source": [
        "#@title üöÄ **STEP 4: START THE AI AUTOMATION SUITE!** {display-mode: \"form\"}\n",
        "#@markdown This starts the WebUI with API access and creates public URLs\n",
        "\n",
        "ngrok_token = \"2xXSbY7GuqGy43bQrTtHQCroZHd_3FeQ77r69WQWUhJnkXYgz\" #@param {type:\"string\"}\n",
        "#@markdown Get your free token at: https://ngrok.com/ (optional but recommended)\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def run_cmd(command):\n",
        "    \"\"\"Execute shell command and return output\"\"\"\n",
        "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "    return result.stdout\n",
        "\n",
        "print(\"üöÄ LAUNCHING AI AUTOMATION SUITE!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Install pyngrok if needed and configure token\n",
        "if ngrok_token:\n",
        "    try:\n",
        "        from pyngrok import ngrok, conf\n",
        "    except ImportError:\n",
        "        print(\"‚è≥ Installing pyngrok...\")\n",
        "        run_cmd(\"pip install pyngrok\")\n",
        "        from pyngrok import ngrok, conf\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    conf.get_default().region = \"us\"  # Set default region\n",
        "    print(\"‚úÖ ngrok token configured\")\n",
        "\n",
        "# Create WebUI startup script\n",
        "webui_script = '''#!/bin/bash\n",
        "cd /content/stable-diffusion-webui\n",
        "python launch.py --share --api --xformers --enable-insecure-extension-access --theme dark --gradio-queue\n",
        "'''\n",
        "\n",
        "# Write startup script\n",
        "with open('/content/start_webui.sh', 'w') as f:\n",
        "    f.write(webui_script)\n",
        "\n",
        "# Make executable\n",
        "run_cmd('chmod +x /content/start_webui.sh')\n",
        "\n",
        "print(\"üé® Starting Stable Diffusion WebUI...\")\n",
        "print(\"‚è≥ This may take 5-10 minutes on first run...\")\n",
        "\n",
        "# Start WebUI in background\n",
        "webui_process = subprocess.Popen(\n",
        "    ['bash', '/content/start_webui.sh'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "# Function to monitor WebUI logs\n",
        "def log_webui_output():\n",
        "    while True:\n",
        "        output = webui_process.stdout.readline()\n",
        "        if output == '' and webui_process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip())\n",
        "    webui_process.poll()\n",
        "\n",
        "# Start log monitoring in separate thread\n",
        "log_thread = threading.Thread(target=log_webui_output, daemon=True)\n",
        "log_thread.start()\n",
        "\n",
        "# Wait for WebUI to start\n",
        "print(\"‚è≥ Waiting for WebUI to initialize...\")\n",
        "api_ready = False\n",
        "max_attempts = 120\n",
        "attempt = 0\n",
        "\n",
        "while not api_ready and attempt < max_attempts:\n",
        "    try:\n",
        "        response = requests.get('http://localhost:7860', timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            api_ready = True\n",
        "            break\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    time.sleep(10)\n",
        "    attempt += 1\n",
        "    print(f\"‚è≥ Still starting... ({attempt}/{max_attempts})\")\n",
        "\n",
        "if api_ready:\n",
        "    print(\"‚úÖ WebUI is running!\")\n",
        "\n",
        "    # Setup ngrok tunnel if token provided\n",
        "    public_url = \"http://localhost:7860\"\n",
        "    if ngrok_token:\n",
        "        print(\"üåê Creating public tunnel...\")\n",
        "        try:\n",
        "            tunnel = ngrok.connect(addr=\"7860\", proto=\"http\", bind_tls=True)\n",
        "            public_url = tunnel.public_url\n",
        "            print(f\"üîó ngrok tunnel created: {public_url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è ngrok tunnel failed: {str(e)}\")\n",
        "            print(\"üîå Using local connection only\")\n",
        "\n",
        "    print(\"\\nüéâ AI AUTOMATION SUITE IS LIVE!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"üé® WebUI Interface: {public_url}\")\n",
        "    print(f\"üîå API Endpoint: {public_url}/sdapi/v1\")\n",
        "    print(f\"üìñ API Docs: {public_url}/docs\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Save URLs for later use\n",
        "    urls = {\n",
        "        'webui_url': public_url,\n",
        "        'api_base': f'{public_url}/sdapi/v1',\n",
        "        'api_docs': f'{public_url}/docs'\n",
        "    }\n",
        "\n",
        "    with open('/content/api_urls.json', 'w') as f:\n",
        "        json.dump(urls, f, indent=2)\n",
        "\n",
        "    print(\"üí° NEXT STEPS:\")\n",
        "    print(\"1. Click the WebUI link above to access the interface\")\n",
        "    print(\"2. Use the API endpoint in your n8n workflows\")\n",
        "    print(\"3. Run the test generation below\")\n",
        "    print(\"\\nüî• YOUR AI AUTOMATION EMPIRE IS READY! üî•\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Failed to start WebUI. Possible causes:\")\n",
        "    print(\"- Out of VRAM (try restarting runtime)\")\n",
        "    print(\"- Missing dependencies (check logs above)\")\n",
        "    print(\"- Port conflict (try changing port)\")\n",
        "    print(\"Check full logs above for troubleshooting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4VYT1M8bK85"
      },
      "outputs": [],
      "source": [
        "#@title üß™ **STEP 5: Test Your AI API** {display-mode: \"form\"}\n",
        "#@markdown Generates a test image to verify everything is working\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Load API URLs\n",
        "try:\n",
        "    with open('/content/api_urls.json', 'r') as f:\n",
        "            urls = json.load(f)\n",
        "                api_base = urls['api_base']\n",
        "                except:\n",
        "                    api_base = 'http://localhost:7860/sdapi/v1'\n",
        "\n",
        "                    print(\"üß™ Testing AI API...\")\n",
        "                    print(f\"üîå Using API: {api_base}\")\n",
        "\n",
        "                    # Test generation payload\n",
        "                    payload = {\n",
        "                        \"prompt\": \"a beautiful cyberpunk city at night, neon lights, highly detailed, 8k, cinematic lighting\",\n",
        "                            \"negative_prompt\": \"blurry, low quality, distorted, ugly\",\n",
        "                                \"width\": 512,\n",
        "                                    \"height\": 512,\n",
        "                                        \"steps\": 20,\n",
        "                                            \"cfg_scale\": 7.0,\n",
        "                                                \"sampler_name\": \"DPM++ 2M Karras\",\n",
        "                                                    \"seed\": -1\n",
        "                                                    }\n",
        "\n",
        "                                                    try:\n",
        "                                                        print(\"üé® Generating test image...\")\n",
        "                                                            response = requests.post(f\"{api_base}/txt2img\", json=payload, timeout=300)\n",
        "\n",
        "                                                                    if response.status_code == 200:\n",
        "                                                                            result = response.json()\n",
        "\n",
        "                                                                                            if 'images' in result and len(result['images']) > 0:\n",
        "                                                                                                        # Decode and display the image\n",
        "                                                                                                                    image_data = result['images'][0]\n",
        "                                                                                                                                image_bytes = base64.b64decode(image_data)\n",
        "                                                                                                                                            image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "                                                                                                                                                                    # Save the image\n",
        "                                                                                                                                                                                image.save('/content/test_generation.png')\n",
        "\n",
        "                                                                                                                                                                                                        print(\"‚úÖ TEST SUCCESSFUL!\")\n",
        "                                                                                                                                                                                                                    print(\"üé® Test image generated and saved as 'test_generation.png'\")\n",
        "                                                                                                                                                                                                                                print(\"üî• Your AI automation suite is working perfectly!\")\n",
        "\n",
        "                                                                                                                                                                                                                                                        # Display the image\n",
        "                                                                                                                                                                                                                                                                    from IPython.display import display\n",
        "                                                                                                                                                                                                                                                                                display(image)\n",
        "\n",
        "                                                                                                                                                                                                                                                                                                    else:\n",
        "                                                                                                                                                                                                                                                                                                                print(\"‚ùå No images in response\")\n",
        "                                                                                                                                                                                                                                                                                                                    else:\n",
        "                                                                                                                                                                                                                                                                                                                            print(f\"‚ùå API Error: {response.status_code}\")\n",
        "                                                                                                                                                                                                                                                                                                                                    print(response.text)\n",
        "\n",
        "                                                                                                                                                                                                                                                                                                                                            except Exception as e:\n",
        "                                                                                                                                                                                                                                                                                                                                                print(f\"‚ùå Test failed: {e}\")\n",
        "                                                                                                                                                                                                                                                                                                                                                    print(\"Make sure the WebUI is running from the previous step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktWrYPBoJcKI"
      },
      "outputs": [],
      "source": [
        "#@title üé¨ **STEP 6: Install Video Animation Dependencies** {display-mode: \"form\"}\n",
        "#@markdown Install additional packages for whiteboard animation generation\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "print(\"üé¨ Installing video animation dependencies...\")\n",
        "\n",
        "# Video processing and animation libraries\n",
        "packages = [\n",
        "    \"opencv-python-headless\",\n",
        "    \"moviepy\",\n",
        "    \"imageio[ffmpeg]\",\n",
        "    \"pydub\",\n",
        "    \"scikit-image\",\n",
        "    \"numpy\",\n",
        "    \"matplotlib\",\n",
        "    \"Pillow\"\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        install_package(package)\n",
        "        print(f\"‚úÖ {package} installed\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "\n",
        "print(\"‚úÖ Video animation dependencies installed!\")\n",
        "\n",
        "# Verify FFmpeg installation\n",
        "try:\n",
        "    result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(\"‚úÖ FFmpeg is available\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Installing FFmpeg...\")\n",
        "        run_cmd(\"apt-get install -y ffmpeg\")\n",
        "        print(\"‚úÖ FFmpeg installed\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è Installing FFmpeg...\")\n",
        "    run_cmd(\"apt-get install -y ffmpeg\")\n",
        "    print(\"‚úÖ FFmpeg installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxrVJBV7JcKI"
      },
      "outputs": [],
      "source": [
        "#@title üé® **STEP 7: Whiteboard Animation Engine** {display-mode: \"form\"}\n",
        "#@markdown Core functions for generating whiteboard-style animations\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.morphology import skeletonize\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class WhiteboardAnimator:\n",
        "    def __init__(self, width=1024, height=768, fps=24):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.fps = fps\n",
        "\n",
        "    def generate_whiteboard_image(self, prompt, api_base):\n",
        "        \"\"\"Generate whiteboard-style image using Stable Diffusion\"\"\"\n",
        "\n",
        "        # Enhanced whiteboard prompt\n",
        "        whiteboard_prompt = f\"\"\"\n",
        "        whiteboard drawing, clean black line art on white background,\n",
        "        simple sketch style, hand-drawn illustration, educational diagram,\n",
        "        {prompt}, monochrome, no color, no shading, minimalist line art,\n",
        "        doodle style, marker drawing, classroom whiteboard\n",
        "        \"\"\"\n",
        "\n",
        "        negative_prompt = \"\"\"\n",
        "        color, colored, shading, shadows, 3d, realistic, photographic,\n",
        "        complex details, cluttered, messy, blurry, low quality\n",
        "        \"\"\"\n",
        "\n",
        "        payload = {\n",
        "            \"prompt\": whiteboard_prompt,\n",
        "            \"negative_prompt\": negative_prompt,\n",
        "            \"width\": self.width,\n",
        "            \"height\": self.height,\n",
        "            \"steps\": 25,\n",
        "            \"cfg_scale\": 8.0,\n",
        "            \"sampler_name\": \"DPM++ 2M Karras\",\n",
        "            \"seed\": 42  # Fixed seed for consistency\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            import requests\n",
        "            import base64\n",
        "            from io import BytesIO\n",
        "\n",
        "            response = requests.post(f\"{api_base}/txt2img\", json=payload, timeout=300)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                if 'images' in result and len(result['images']) > 0:\n",
        "                    image_data = result['images'][0]\n",
        "                    image_bytes = base64.b64decode(image_data)\n",
        "                    image = Image.open(BytesIO(image_bytes))\n",
        "                    return np.array(image)\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error generating image: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_drawing_path(self, image):\n",
        "        \"\"\"Extract optimal drawing path from image using edge detection\"\"\"\n",
        "\n",
        "        # Convert to grayscale\n",
        "        if len(image.shape) == 3:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = image\n",
        "\n",
        "        # Edge detection\n",
        "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "\n",
        "        # Find contours for drawing path\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Sort contours by area (draw larger elements first)\n",
        "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "        # Generate drawing path\n",
        "        drawing_path = []\n",
        "        for contour in contours:\n",
        "            if cv2.contourArea(contour) > 100:  # Filter small noise\n",
        "                # Simplify contour to reduce points\n",
        "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "                simplified = cv2.approxPolyDP(contour, epsilon, True)\n",
        "                drawing_path.extend(simplified.reshape(-1, 2))\n",
        "\n",
        "        return drawing_path\n",
        "\n",
        "    def generate_animation_frames(self, base_image, drawing_path, duration_seconds):\n",
        "        \"\"\"Generate progressive reveal animation frames\"\"\"\n",
        "\n",
        "        total_frames = int(duration_seconds * self.fps)\n",
        "        frames = []\n",
        "\n",
        "        # Create base canvas\n",
        "        canvas = np.ones_like(base_image) * 255  # White background\n",
        "\n",
        "        if len(drawing_path) == 0:\n",
        "            # Fallback: simple left-to-right reveal\n",
        "            for frame_idx in range(total_frames):\n",
        "                progress = (frame_idx + 1) / total_frames\n",
        "                reveal_width = int(self.width * progress)\n",
        "\n",
        "                frame = canvas.copy()\n",
        "                frame[:, :reveal_width] = base_image[:, :reveal_width]\n",
        "                frames.append(frame)\n",
        "        else:\n",
        "            # Path-based drawing animation\n",
        "            points_per_frame = max(1, len(drawing_path) // total_frames)\n",
        "\n",
        "            for frame_idx in range(total_frames):\n",
        "                frame = canvas.copy()\n",
        "\n",
        "                # Calculate how many points to reveal\n",
        "                points_to_reveal = min(len(drawing_path), (frame_idx + 1) * points_per_frame)\n",
        "\n",
        "                # Create mask from revealed points\n",
        "                mask = np.zeros((self.height, self.width), dtype=np.uint8)\n",
        "\n",
        "                for i in range(0, points_to_reveal, 2):\n",
        "                    if i + 1 < len(drawing_path):\n",
        "                        pt1 = tuple(drawing_path[i])\n",
        "                        pt2 = tuple(drawing_path[i + 1])\n",
        "                        cv2.line(mask, pt1, pt2, 255, 3)\n",
        "\n",
        "                # Dilate mask for better coverage\n",
        "                kernel = np.ones((5, 5), np.uint8)\n",
        "                mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "                # Apply mask to reveal parts of the image\n",
        "                frame[mask > 0] = base_image[mask > 0]\n",
        "                frames.append(frame)\n",
        "\n",
        "        return frames\n",
        "\n",
        "    def add_drawing_hand(self, frames):\n",
        "        \"\"\"Add animated drawing hand cursor to frames\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Simple hand cursor (you can replace with actual hand image)\n",
        "            hand_size = 30\n",
        "\n",
        "            for i, frame in enumerate(frames):\n",
        "                # Calculate hand position (moves across screen)\n",
        "                progress = i / len(frames)\n",
        "                x = int(self.width * progress * 0.8 + 50)\n",
        "                y = int(self.height * 0.7)\n",
        "\n",
        "                # Draw simple hand cursor\n",
        "                cv2.circle(frame, (x, y), hand_size, (150, 150, 150), -1)\n",
        "                cv2.circle(frame, (x, y), hand_size-5, (200, 200, 200), -1)\n",
        "\n",
        "                # Add pointer\n",
        "                cv2.circle(frame, (x+10, y-10), 5, (100, 100, 100), -1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not add hand animation: {e}\")\n",
        "\n",
        "        return frames\n",
        "\n",
        "# Initialize the animator\n",
        "print(\"üé® Whiteboard Animation Engine Loaded!\")\n",
        "print(\"‚úÖ Ready to generate whiteboard-style videos!\")\n",
        "\n",
        "# Create global animator instance\n",
        "animator = WhiteboardAnimator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7_YYfkrJcKJ"
      },
      "outputs": [],
      "source": [
        "#@title üé¨ **STEP 8: Video Generation Pipeline** {display-mode: \"form\"}\n",
        "#@markdown Complete pipeline for generating whiteboard animation videos\n",
        "\n",
        "import subprocess\n",
        "import tempfile\n",
        "import shutil\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, concatenate_audioclips\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import json\n",
        "\n",
        "class VideoGenerator:\n",
        "    def __init__(self, output_dir=\"/content/videos\", temp_dir=\"/content/temp\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.temp_dir = Path(temp_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        self.temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def get_audio_duration(self, audio_file):\n",
        "        \"\"\"Get duration of audio file in seconds\"\"\"\n",
        "        try:\n",
        "            # Try with pydub first\n",
        "            audio = AudioSegment.from_file(audio_file)\n",
        "            return len(audio) / 1000.0  # Convert ms to seconds\n",
        "        except:\n",
        "            try:\n",
        "                # Fallback to ffprobe\n",
        "                cmd = [\n",
        "                    'ffprobe', '-v', 'quiet', '-show_entries',\n",
        "                    'format=duration', '-of', 'csv=p=0', str(audio_file)\n",
        "                ]\n",
        "                result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "                return float(result.stdout.strip())\n",
        "            except:\n",
        "                print(f\"‚ö†Ô∏è Could not get duration for {audio_file}, using default 3 seconds\")\n",
        "                return 3.0\n",
        "\n",
        "    def generate_scene_video(self, scene_data, api_base, include_hand=True):\n",
        "        \"\"\"Generate video for a single micro-scene\"\"\"\n",
        "\n",
        "        scene_id = scene_data.get('id', str(uuid.uuid4()))\n",
        "        scene_description = scene_data.get('description', '')\n",
        "        audio_file = scene_data.get('audio_file', None)\n",
        "\n",
        "        print(f\"üé¨ Generating video for scene: {scene_id}\")\n",
        "\n",
        "        # Get audio duration\n",
        "        if audio_file and os.path.exists(audio_file):\n",
        "            duration = self.get_audio_duration(audio_file)\n",
        "        else:\n",
        "            duration = 3.0  # Default duration\n",
        "            print(f\"‚ö†Ô∏è No audio file provided, using {duration}s duration\")\n",
        "\n",
        "        # Generate whiteboard image\n",
        "        print(f\"üé® Generating whiteboard image...\")\n",
        "        base_image = animator.generate_whiteboard_image(scene_description, api_base)\n",
        "\n",
        "        if base_image is None:\n",
        "            print(f\"‚ùå Failed to generate image for scene {scene_id}\")\n",
        "            return None\n",
        "\n",
        "        # Extract drawing path\n",
        "        print(f\"üéØ Extracting drawing path...\")\n",
        "        drawing_path = animator.extract_drawing_path(base_image)\n",
        "\n",
        "        # Generate animation frames\n",
        "        print(f\"üéûÔ∏è Generating {duration}s animation ({int(duration * animator.fps)} frames)...\")\n",
        "        frames = animator.generate_animation_frames(base_image, drawing_path, duration)\n",
        "\n",
        "        # Add drawing hand if requested\n",
        "        if include_hand:\n",
        "            print(f\"‚úã Adding drawing hand animation...\")\n",
        "            frames = animator.add_drawing_hand(frames)\n",
        "\n",
        "        # Save frames to temporary directory\n",
        "        frame_dir = self.temp_dir / f\"frames_{scene_id}\"\n",
        "        frame_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        for i, frame in enumerate(frames):\n",
        "            frame_path = frame_dir / f\"frame_{i:04d}.png\"\n",
        "            cv2.imwrite(str(frame_path), cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Create video from frames using ffmpeg\n",
        "        video_path = self.output_dir / f\"scene_{scene_id}.mp4\"\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-y',\n",
        "            '-framerate', str(animator.fps),\n",
        "            '-i', str(frame_dir / 'frame_%04d.png'),\n",
        "            '-c:v', 'libx264',\n",
        "            '-pix_fmt', 'yuv420p',\n",
        "            '-crf', '18',  # High quality\n",
        "            str(video_path)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            subprocess.run(cmd, check=True, capture_output=True)\n",
        "            print(f\"‚úÖ Scene video created: {video_path}\")\n",
        "\n",
        "            # Clean up frames\n",
        "            shutil.rmtree(frame_dir)\n",
        "\n",
        "            return {\n",
        "                'video_path': str(video_path),\n",
        "                'audio_file': audio_file,\n",
        "                'duration': duration,\n",
        "                'scene_id': scene_id\n",
        "            }\n",
        "\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå FFmpeg error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def combine_scene_videos(self, scene_videos, output_path=None):\n",
        "        \"\"\"Combine multiple scene videos with their audio into final video\"\"\"\n",
        "\n",
        "        if not scene_videos:\n",
        "            print(\"‚ùå No scene videos to combine\")\n",
        "            return None\n",
        "\n",
        "        if output_path is None:\n",
        "            output_path = self.output_dir / f\"final_video_{uuid.uuid4().hex[:8]}.mp4\"\n",
        "\n",
        "        print(f\"üé¨ Combining {len(scene_videos)} scene videos...\")\n",
        "\n",
        "        try:\n",
        "            video_clips = []\n",
        "            audio_clips = []\n",
        "\n",
        "            for i, scene in enumerate(scene_videos):\n",
        "                if scene is None:\n",
        "                    continue\n",
        "\n",
        "                print(f\"üìπ Processing scene {i+1}/{len(scene_videos)}\")\n",
        "\n",
        "                # Load video\n",
        "                video_clip = VideoFileClip(scene['video_path'])\n",
        "                video_clips.append(video_clip)\n",
        "\n",
        "                # Load audio if available\n",
        "                if scene['audio_file'] and os.path.exists(scene['audio_file']):\n",
        "                    audio_clip = AudioFileClip(scene['audio_file'])\n",
        "                    # Ensure audio matches video duration\n",
        "                    if audio_clip.duration != video_clip.duration:\n",
        "                        audio_clip = audio_clip.subclip(0, min(audio_clip.duration, video_clip.duration))\n",
        "                    audio_clips.append(audio_clip)\n",
        "                else:\n",
        "                    # Create silent audio for this duration\n",
        "                    audio_clips.append(AudioFileClip(None).set_duration(video_clip.duration))\n",
        "\n",
        "            # Concatenate videos\n",
        "            final_video = concatenate_videoclips(video_clips)\n",
        "\n",
        "            # Concatenate audio\n",
        "            if audio_clips:\n",
        "                final_audio = concatenate_audioclips(audio_clips)\n",
        "                final_video = final_video.set_audio(final_audio)\n",
        "\n",
        "            # Write final video\n",
        "            final_video.write_videofile(\n",
        "                str(output_path),\n",
        "                fps=animator.fps,\n",
        "                codec='libx264',\n",
        "                audio_codec='aac'\n",
        "            )\n",
        "\n",
        "            # Clean up\n",
        "            for clip in video_clips + audio_clips:\n",
        "                clip.close()\n",
        "            final_video.close()\n",
        "\n",
        "            print(f\"üéâ Final video created: {output_path}\")\n",
        "            return str(output_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error combining videos: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_micro_scenes(self, scenes_data, api_base):\n",
        "        \"\"\"Process all micro-scenes and generate final video\"\"\"\n",
        "\n",
        "        print(f\"üöÄ Processing {len(scenes_data)} micro-scenes...\")\n",
        "\n",
        "        scene_videos = []\n",
        "\n",
        "        for i, scene in enumerate(scenes_data):\n",
        "            print(f\"\\nüìã Processing scene {i+1}/{len(scenes_data)}\")\n",
        "            video_result = self.generate_scene_video(scene, api_base)\n",
        "            scene_videos.append(video_result)\n",
        "\n",
        "        # Combine all scene videos\n",
        "        final_video_path = self.combine_scene_videos(scene_videos)\n",
        "\n",
        "        return final_video_path\n",
        "\n",
        "# Initialize video generator\n",
        "video_generator = VideoGenerator()\n",
        "print(\"üé¨ Video Generation Pipeline Ready!\")\n",
        "print(f\"üìÅ Output directory: {video_generator.output_dir}\")\n",
        "print(\"‚úÖ Ready to process micro-scenes!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEi5tSipJcKJ"
      },
      "outputs": [],
      "source": [
        "#@title üß™ **STEP 9: Test Whiteboard Animation** {display-mode: \"form\"}\n",
        "#@markdown Generate a sample whiteboard animation video with multiple scenes\n",
        "\n",
        "# Sample micro-scenes data (replace with your actual data from Notion/n8n)\n",
        "sample_scenes = [\n",
        "    {\n",
        "        'id': 'scene_001',\n",
        "        'description': 'A businessman analyzing charts and graphs on a computer screen, showing data trends and analytics',\n",
        "        'audio_file': None,  # You can provide path to audio file here\n",
        "        'duration': 4.0  # seconds\n",
        "    },\n",
        "    {\n",
        "        'id': 'scene_002',\n",
        "        'description': 'Team meeting with people discussing strategy around a table, arrows showing workflow processes',\n",
        "        'audio_file': None,\n",
        "        'duration': 3.5\n",
        "    },\n",
        "    {\n",
        "        'id': 'scene_003',\n",
        "        'description': 'Growth arrow pointing upward with dollar signs and success symbols, representing business growth',\n",
        "        'audio_file': None,\n",
        "        'duration': 3.0\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üß™ Testing Whiteboard Animation Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load API URLs\n",
        "try:\n",
        "    with open('/content/api_urls.json', 'r') as f:\n",
        "        urls = json.load(f)\n",
        "    api_base = urls['api_base']\n",
        "    print(f\"‚úÖ Using API: {api_base}\")\n",
        "except:\n",
        "    api_base = 'http://localhost:7860/sdapi/v1'\n",
        "    print(f\"‚ö†Ô∏è Using default API: {api_base}\")\n",
        "\n",
        "# Test single scene generation first\n",
        "print(f\"\\nüé¨ Testing single scene generation...\")\n",
        "test_scene = sample_scenes[0]\n",
        "\n",
        "single_video = video_generator.generate_scene_video(\n",
        "    test_scene,\n",
        "    api_base,\n",
        "    include_hand=True\n",
        ")\n",
        "\n",
        "if single_video:\n",
        "    print(f\"‚úÖ Single scene test successful!\")\n",
        "    print(f\"üìπ Video saved: {single_video['video_path']}\")\n",
        "\n",
        "    # Display the video info\n",
        "    from IPython.display import HTML, display\n",
        "    video_path = single_video['video_path']\n",
        "\n",
        "    display(HTML(f'''\n",
        "    <video width=\"512\" height=\"384\" controls>\n",
        "        <source src=\"{video_path}\" type=\"video/mp4\">\n",
        "        Your browser does not support the video tag.\n",
        "    </video>\n",
        "    <p><strong>Scene ID:</strong> {single_video['scene_id']}</p>\n",
        "    <p><strong>Duration:</strong> {single_video['duration']} seconds</p>\n",
        "    '''))\n",
        "\n",
        "    # Now test full pipeline with all scenes\n",
        "    print(f\"\\nüöÄ Testing full pipeline with {len(sample_scenes)} scenes...\")\n",
        "\n",
        "    final_video_path = video_generator.process_micro_scenes(sample_scenes, api_base)\n",
        "\n",
        "    if final_video_path:\n",
        "        print(f\"\\nüéâ SUCCESS! Full whiteboard animation created!\")\n",
        "        print(f\"üìΩÔ∏è Final video: {final_video_path}\")\n",
        "\n",
        "        # Display final video\n",
        "        display(HTML(f'''\n",
        "        <h3>üé¨ Final Whiteboard Animation</h3>\n",
        "        <video width=\"512\" height=\"384\" controls>\n",
        "            <source src=\"{final_video_path}\" type=\"video/mp4\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        <p><strong>Total Scenes:</strong> {len(sample_scenes)}</p>\n",
        "        <p><strong>Total Duration:</strong> {sum(s.get('duration', 3.0) for s in sample_scenes)} seconds</p>\n",
        "        '''))\n",
        "\n",
        "        print(\"\\nüí° NEXT STEPS:\")\n",
        "        print(\"1. Replace sample_scenes with your actual micro-scene data\")\n",
        "        print(\"2. Add audio files to each scene\")\n",
        "        print(\"3. Integrate with your n8n workflow\")\n",
        "        print(\"4. Customize animation styles and timing\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Failed to create full video\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Single scene test failed\")\n",
        "    print(\"Make sure the Stable Diffusion API is running from Step 4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3rAUaOKJcKL"
      },
      "outputs": [],
      "source": [
        "#@title üåê **STEP 10: n8n Integration API** {display-mode: \"form\"}\n",
        "#@markdown Create webhook endpoint for n8n workflow integration\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "import threading\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "class VideoGenerationAPI:\n",
        "    def __init__(self, port=5000):\n",
        "        self.app = Flask(__name__)\n",
        "        self.port = port\n",
        "        self.setup_routes()\n",
        "\n",
        "    def setup_routes(self):\n",
        "        @self.app.route('/health', methods=['GET'])\n",
        "        def health_check():\n",
        "            return jsonify({\n",
        "                'status': 'healthy',\n",
        "                'services': {\n",
        "                    'stable_diffusion': self.check_sd_api(),\n",
        "                    'video_generator': True\n",
        "                }\n",
        "            })\n",
        "\n",
        "        @self.app.route('/generate-video', methods=['POST'])\n",
        "        def generate_video_endpoint():\n",
        "            try:\n",
        "                data = request.json\n",
        "\n",
        "                # Validate input\n",
        "                if 'scenes' not in data:\n",
        "                    return jsonify({'error': 'scenes data required'}), 400\n",
        "\n",
        "                scenes = data['scenes']\n",
        "                project_id = data.get('project_id', 'default')\n",
        "\n",
        "                # Load API URLs\n",
        "                try:\n",
        "                    with open('/content/api_urls.json', 'r') as f:\n",
        "                        urls = json.load(f)\n",
        "                    api_base = urls['api_base']\n",
        "                except:\n",
        "                    api_base = 'http://localhost:7860/sdapi/v1'\n",
        "\n",
        "                # Process scenes\n",
        "                final_video_path = video_generator.process_micro_scenes(scenes, api_base)\n",
        "\n",
        "                if final_video_path:\n",
        "                    return jsonify({\n",
        "                        'success': True,\n",
        "                        'video_path': final_video_path,\n",
        "                        'project_id': project_id,\n",
        "                        'scenes_count': len(scenes)\n",
        "                    })\n",
        "                else:\n",
        "                    return jsonify({'error': 'Video generation failed'}), 500\n",
        "\n",
        "            except Exception as e:\n",
        "                return jsonify({'error': str(e)}), 500\n",
        "\n",
        "        @self.app.route('/generate-scene', methods=['POST'])\n",
        "        def generate_scene_endpoint():\n",
        "            try:\n",
        "                data = request.json\n",
        "\n",
        "                # Load API URLs\n",
        "                try:\n",
        "                    with open('/content/api_urls.json', 'r') as f:\n",
        "                        urls = json.load(f)\n",
        "                    api_base = urls['api_base']\n",
        "                except:\n",
        "                    api_base = 'http://localhost:7860/sdapi/v1'\n",
        "\n",
        "                # Generate single scene\n",
        "                result = video_generator.generate_scene_video(data, api_base)\n",
        "\n",
        "                if result:\n",
        "                    return jsonify({\n",
        "                        'success': True,\n",
        "                        'scene_video': result\n",
        "                    })\n",
        "                else:\n",
        "                    return jsonify({'error': 'Scene generation failed'}), 500\n",
        "\n",
        "            except Exception as e:\n",
        "                return jsonify({'error': str(e)}), 500\n",
        "\n",
        "    def check_sd_api(self):\n",
        "        try:\n",
        "            import requests\n",
        "            response = requests.get('http://localhost:7860/', timeout=5)\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def run(self):\n",
        "        self.app.run(host='0.0.0.0', port=self.port, debug=False)\n",
        "\n",
        "# Initialize API\n",
        "api = VideoGenerationAPI()\n",
        "\n",
        "print(\"üåê Setting up n8n Integration API...\")\n",
        "\n",
        "# Start API in background thread\n",
        "api_thread = threading.Thread(target=api.run, daemon=True)\n",
        "api_thread.start()\n",
        "\n",
        "# Give Flask time to start\n",
        "time.sleep(3)\n",
        "\n",
        "# Create ngrok tunnel for the API\n",
        "try:\n",
        "    api_tunnel = ngrok.connect(5000)\n",
        "    api_url = str(api_tunnel)\n",
        "\n",
        "    print(\"üéâ VIDEO GENERATION API IS LIVE!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"üåê API Base URL: {api_url}\")\n",
        "    print(f\"üîó Health Check: {api_url}/health\")\n",
        "    print(f\"üé¨ Generate Video: {api_url}/generate-video\")\n",
        "    print(f\"üéØ Generate Scene: {api_url}/generate-scene\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Save API info\n",
        "    api_info = {\n",
        "        'api_url': api_url,\n",
        "        'endpoints': {\n",
        "            'health': f'{api_url}/health',\n",
        "            'generate_video': f'{api_url}/generate-video',\n",
        "            'generate_scene': f'{api_url}/generate-scene'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open('/content/video_api_info.json', 'w') as f:\n",
        "        json.dump(api_info, f, indent=2)\n",
        "\n",
        "    print(\"üìã Example n8n HTTP Request Node Configuration:\")\n",
        "    print(\"\"\"\n",
        "    {\n",
        "      \"method\": \"POST\",\n",
        "      \"url\": \\\"\"\"\" + f\"{api_url}/generate-video\" + \"\"\"\\\",\n",
        "      \"body\": {\n",
        "        \"project_id\": \"{{$json.project_id}}\",\n",
        "        \"scenes\": [\n",
        "          {\n",
        "            \"id\": \"scene_001\",\n",
        "            \"description\": \"{{$json.scene_description}}\",\n",
        "            \"audio_file\": \"{{$json.audio_file_path}}\",\n",
        "            \"duration\": {{$json.duration}}\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      \"headers\": {\n",
        "        \"Content-Type\": \"application/json\"\n",
        "      }\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nüìù Example Notion to Video Workflow:\")\n",
        "    print(\"\"\"\n",
        "    1. Notion Trigger: When database item updated\n",
        "    2. Get all micro-scenes for project\n",
        "    3. HTTP Request to generate-video endpoint\n",
        "    4. Update Notion with video URL\n",
        "    5. Send notification (Slack/email)\n",
        "    \"\"\")\n",
        "\n",
        "    print(f\"\\nüî• YOUR COMPLETE AI VIDEO AUTOMATION SUITE IS READY!\")\n",
        "    print(\"‚úÖ Stable Diffusion WebUI running\")\n",
        "    print(\"‚úÖ Whiteboard animation engine active\")\n",
        "    print(\"‚úÖ Video generation API live\")\n",
        "    print(\"‚úÖ n8n integration ready\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to create API tunnel: {e}\")\n",
        "    print(\"üåê API is running locally on: http://localhost:5000\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hll9v7L9JcKL"
      },
      "outputs": [],
      "source": [
        "# üéâ COMPLETE AI WHITEBOARD ANIMATION PIPELINE\n",
        "\n",
        "## üî• CONGRATULATIONS! YOUR AI AUTOMATION EMPIRE IS READY!\n",
        "\n",
        "You now have a **COMPLETE END-TO-END AI VIDEO GENERATION PIPELINE** that transforms any topic into professional whiteboard animations!\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ WHAT YOU'VE BUILT\n",
        "\n",
        "### **Stage 1: Script & Scene Generation (Your Existing n8n Workflows)**\n",
        "- ‚úÖ **Macro-Scene Script Generation**: Topic ‚Üí Full script breakdown\n",
        "- ‚úÖ **Scene-to-Micro-Scene Processing**: Scene breakdown with indexing\n",
        "- ‚úÖ **Metadata & Audio Preprocessing**: ElevenLabs voice preparation\n",
        "\n",
        "### **Stage 2: Visual & Video Generation (This Colab Pipeline)**\n",
        "- ‚úÖ **Stable Diffusion WebUI**: Professional image generation\n",
        "- ‚úÖ **Whiteboard Animation Engine**: Progressive reveal animations\n",
        "- ‚úÖ **Video Generation Pipeline**: Audio-synced scene compilation\n",
        "- ‚úÖ **n8n Integration API**: Seamless workflow integration\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ COMPLETE AUTOMATION WORKFLOW\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[Topic Input] --> B[n8n: Macro Script Generation]\n",
        "    B --> C[n8n: Micro-Scene Breakdown]\n",
        "    C --> D[n8n: ElevenLabs Audio Generation]\n",
        "    D --> E[n8n: Trigger Video Generation]\n",
        "    E --> F[Colab: Generate Whiteboard Images]\n",
        "    F --> G[Colab: Create Animations]\n",
        "    G --> H[Colab: Sync Audio & Compile Video]\n",
        "    H --> I[Final Professional Video]\n",
        "\n",
        "    style A fill:#ff9999\n",
        "    style I fill:#99ff99\n",
        "    style E fill:#ffff99\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üåê INTEGRATION WITH YOUR n8n WORKFLOWS\n",
        "\n",
        "### **Step 1: Connect to Your Existing Workflows**\n",
        "\n",
        "Add this **HTTP Request Node** to your existing n8n workflows:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"method\": \"POST\",\n",
        "  \"url\": \"YOUR_COLAB_API_URL/generate-video\",\n",
        "  \"headers\": {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "  },\n",
        "  \"body\": {\n",
        "    \"project_id\": \"{{ $json.project_id }}\",\n",
        "    \"scenes\": \"{{ $json.micro_scenes }}\"\n",
        "  },\n",
        "  \"timeout\": 600000\n",
        "}\n",
        "```\n",
        "\n",
        "### **Step 2: Notion Data Mapping**\n",
        "\n",
        "Your existing Notion **MICRO_SCENE** table maps perfectly:\n",
        "\n",
        "```javascript\n",
        "// n8n Function Node: Prepare scenes for video generation\n",
        "const scenes = $input.all().map(item => ({\n",
        "  id: item.json.ROW_ID,\n",
        "  description: item.json.scene_description,\n",
        "  audio_file: item.json.audio_url, // From ElevenLabs\n",
        "  duration: item.json.audio_duration\n",
        "}));\n",
        "\n",
        "return { json: { scenes: scenes } };\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üé¨ PROFESSIONAL FEATURES\n",
        "\n",
        "### **Advanced Animation Techniques**\n",
        "- üé® **Whiteboard Style**: Clean black line art on white background\n",
        "- ‚úã **Hand-Drawn Effect**: Animated drawing hand with progressive reveal\n",
        "- üé≠ **Intelligent Path Detection**: Edge-based drawing animation\n",
        "- üéµ **Audio Synchronization**: Perfect timing with ElevenLabs voiceover\n",
        "\n",
        "### **Video Quality Settings**\n",
        "- üì∫ **Resolution**: 1024x768 (scalable to 1080p)\n",
        "- üé¨ **Frame Rate**: 24 fps (cinematic quality)\n",
        "- üîä **Audio**: AAC codec, perfect sync\n",
        "- üíæ **Output**: MP4, YouTube-ready\n",
        "\n",
        "---\n",
        "\n",
        "## üîß PRODUCTION DEPLOYMENT\n",
        "\n",
        "### **Option 1: Google Colab Pro (Recommended)**\n",
        "- ‚úÖ **24+ hour sessions**\n",
        "- ‚úÖ **A100/V100 GPUs**\n",
        "- ‚úÖ **Priority access**\n",
        "- ‚úÖ **Background execution**\n",
        "- üí∞ **Cost**: ~$10/month\n",
        "\n",
        "### **Option 2: Local GPU Setup**\n",
        "```bash\n",
        "# Quick local setup (if you have NVIDIA GPU)\n",
        "git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n",
        "cd stable-diffusion-webui\n",
        "python launch.py --api --share\n",
        "```\n",
        "\n",
        "### **Option 3: Cloud GPU Services**\n",
        "- **RunPod**: ~$0.50/hour GPU\n",
        "- **Vast.ai**: Competitive GPU rental\n",
        "- **AWS/GCP**: Production scaling\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ COMPLETE n8n WORKFLOW EXAMPLE\n",
        "\n",
        "### **Master Video Generation Workflow**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"üé¨ Complete AI Video Pipeline\",\n",
        "  \"nodes\": [\n",
        "    {\n",
        "      \"name\": \"1. Get Project from Notion\",\n",
        "      \"type\": \"Notion\",\n",
        "      \"operation\": \"getAll\",\n",
        "      \"database\": \"MICRO_SCENE\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"2. Generate Audio (ElevenLabs)\",\n",
        "      \"type\": \"HTTP Request\",\n",
        "      \"url\": \"https://api.elevenlabs.io/v1/text-to-speech\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"3. Prepare Video Data\",\n",
        "      \"type\": \"Function\",\n",
        "      \"code\": \"/* Map Notion data to video format */\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"4. Generate Video (Colab)\",\n",
        "      \"type\": \"HTTP Request\",\n",
        "      \"url\": \"YOUR_COLAB_API_URL/generate-video\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"5. Update Notion with Video URL\",\n",
        "      \"type\": \"Notion\",\n",
        "      \"operation\": \"update\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"6. Send Notification\",\n",
        "      \"type\": \"Slack/Email\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä PERFORMANCE METRICS\n",
        "\n",
        "### **Generation Times** (Approximate)\n",
        "- üé® **Image Generation**: 10-30 seconds per scene\n",
        "- üé¨ **Animation Creation**: 20-60 seconds per scene\n",
        "- üéµ **Audio Processing**: 5-15 seconds per scene\n",
        "- üìπ **Video Compilation**: 30-120 seconds total\n",
        "\n",
        "### **Quality Benchmarks**\n",
        "- üéØ **Style Consistency**: 95%+ with fixed seeds\n",
        "- üé≠ **Animation Smoothness**: 24fps fluid motion\n",
        "- üîä **Audio Sync**: <50ms deviation\n",
        "- üì∫ **Output Quality**: Broadcast-ready MP4\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ SCALING STRATEGIES\n",
        "\n",
        "### **High-Volume Production**\n",
        "1. **Multi-Instance Setup**: Run multiple Colab notebooks\n",
        "2. **Queue Management**: Use n8n delay nodes for rate limiting\n",
        "3. **Batch Processing**: Group similar scenes for efficiency\n",
        "4. **Storage Optimization**: Auto-upload to Google Drive/S3\n",
        "\n",
        "### **Enterprise Features**\n",
        "- üé® **Custom Models**: Fine-tune for brand consistency\n",
        "- üé≠ **Style Templates**: Predefined animation styles\n",
        "- üìä **Analytics Dashboard**: Generation metrics\n",
        "- üîÑ **Auto-Retry Logic**: Robust error handling\n",
        "\n",
        "---\n",
        "\n",
        "## üí° REAL-WORLD USE CASES\n",
        "\n",
        "### **Educational Content**\n",
        "- üìö **Course Creation**: Automated lesson videos\n",
        "- üéì **Training Materials**: Corporate learning\n",
        "- üë®‚Äçüè´ **Explainer Videos**: Complex topic simplification\n",
        "\n",
        "### **Marketing & Sales**\n",
        "- üìà **Product Demos**: Automated showcase videos\n",
        "- üéØ **Social Media**: Daily content generation\n",
        "- üì¢ **Ad Campaigns**: Rapid creative iteration\n",
        "\n",
        "### **Content Creation**\n",
        "- üé¨ **YouTube Channels**: Automated educational content\n",
        "- üì± **Social Platforms**: TikTok/Instagram automation\n",
        "- üì∞ **News Explainers**: Current events visualization\n",
        "\n",
        "---\n",
        "\n",
        "## üõ°Ô∏è PRODUCTION CHECKLIST\n",
        "\n",
        "### **Before Going Live**\n",
        "- [ ] Test full pipeline with sample data\n",
        "- [ ] Verify audio-video synchronization\n",
        "- [ ] Check output quality on different devices\n",
        "- [ ] Set up monitoring and alerting\n",
        "- [ ] Configure backup Colab instances\n",
        "- [ ] Test error handling scenarios\n",
        "\n",
        "### **Monitoring & Maintenance**\n",
        "- [ ] Monitor Colab session health\n",
        "- [ ] Track generation success rates\n",
        "- [ ] Optimize prompts for consistency\n",
        "- [ ] Regular model updates\n",
        "- [ ] Performance metrics dashboard\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ SUCCESS! YOU'VE BUILT THE FUTURE\n",
        "\n",
        "### **What You've Achieved**\n",
        "‚úÖ **Full AI automation**: Topic ‚Üí Professional video\n",
        "‚úÖ **Scalable architecture**: Handle multiple projects\n",
        "‚úÖ **Professional quality**: Broadcast-ready output\n",
        "‚úÖ **Cost-effective**: Minimal infrastructure costs\n",
        "‚úÖ **Future-proof**: Easily updatable and expandable\n",
        "\n",
        "### **Next Steps**\n",
        "1. üß™ **Test the complete pipeline** with your existing scripts\n",
        "2. üé® **Customize animation styles** for your brand\n",
        "3. üìä **Set up monitoring** for production use\n",
        "4. üöÄ **Scale to multiple projects**\n",
        "5. üí∞ **Monetize your AI video service**\n",
        "\n",
        "---\n",
        "\n",
        "## üîó RESOURCES & SUPPORT\n",
        "\n",
        "### **Documentation**\n",
        "- üìñ **API Reference**: `/docs` endpoint on your Colab URL\n",
        "- üé¨ **Video Examples**: Generated test animations\n",
        "- üíª **Source Code**: All code available in this notebook\n",
        "- üåê **n8n Templates**: Complete workflow examples\n",
        "\n",
        "### **Community & Updates**\n",
        "- üîÑ **Version Updates**: Regular model improvements\n",
        "- üêõ **Bug Reports**: GitHub issues and discussions\n",
        "- üí° **Feature Requests**: Community-driven development\n",
        "- üéì **Tutorials**: Step-by-step guides and best practices\n",
        "\n",
        "---\n",
        "\n",
        "**üî• CONGRATULATIONS! YOU'VE BUILT A PROFESSIONAL AI VIDEO AUTOMATION EMPIRE! üî•**\n",
        "\n",
        "*From a simple topic input to a complete professional whiteboard animation video - all fully automated with AI!*\n",
        "\n",
        "### üöÄ **YOUR AI AUTOMATION SUITE INCLUDES:**\n",
        "- ‚úÖ Professional Stable Diffusion + ControlNet setup\n",
        "- ‚úÖ Advanced whiteboard animation engine\n",
        "- ‚úÖ Audio-synced video generationgenerationgeneration''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' '''  ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' '''generation pipeline\n",
        "- ‚úÖ Complete n8n workflow integration\n",
        "- ‚úÖ Production-ready API endpointendpointsendpointendpointss''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' '''  ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' ''' '''s\n",
        "- ‚úÖ Scalable cloud deployment\n",
        "roduction-ready API endpoints\n",
        "- ‚úÖ Scalable cloud deployment\n",
        "\n",
        "**Ready to transform any topic into engaging educational videos at scale!** üé¨‚ú®\n",
        "roduction-ready API endpoints\n",
        "- ‚úÖ Scalable cloud deployment\n",
        "\n",
        "**Ready to transform any topic into engaging educational videos at scale!** üé¨‚ú®\n",
        " '''\n",
        "**Ready to transform any topic into engaging educational videos at scale!** üé¨‚ú®\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}